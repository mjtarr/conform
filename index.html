<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="CONFORM - Lahner, Luo, Prince et al.">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="A Project to Create Crowd-Sourced Open Neuroscience fMRI Foundation Models">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content=" Benjamin Lahner, Andrew Luo, Jacob S Prince, Mayukh Deb, Margaret M Henderson, John A Pyles, Leila Wehbe, Aude Oliva, N. Apurva Ratan Murty, Michael J Tarr">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="NEUROAI Community">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="CONFORM">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="A Project to Create Crowd-Sourced Open Neuroscience fMRI Foundation Models">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://mjtarr.github.io/conform">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="CONFORM - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="NEUROAI">
  <meta property="article:tag" content="BRAIN FOUNDATION MODEL">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="CONFORM">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>CONFORM: A Project to Create Crowd-Sourced Open Neuroscience fMRI Foundation Models - Lahner, Luo, Prince, et al. | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <link rel="stylesheet" href="static/css/mystyle.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      Community
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>The CONFORM Community</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://cmu.edu" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Carnegie Mellon University</h5>
            <!-- TODO: Replace with brief description -->
            <p>Margaret Henderson, Michael Tarr, Leila Wehbe</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        
        <a href="https://gatech.edu" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Georgia Institute of Technology</h5>
            <!-- TODO: Replace with brief description -->
            <p>Mayukh Deb, N. Apurva Ratan Murty</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        
        <a href="https://harvard.edu" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Harvard University</h5>
            <!-- TODO: Replace with brief description -->
            <p>Jacob Prince</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>

        <a href="https://www.hku.hk" class="work-item" target="_blank">
          <div class="work-info">
            <h5>University of Hong Kong</h5>
           <!-- TODO: Replace with brief description -->
            <p>Andrew Luo</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>

        <a href="https://mit.edu" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Massachusetts Institute of Technology</h5>
           <!-- TODO: Replace with brief description -->
            <p>Aude Oliva</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
       
        <a href="https://www.washington.edu" class="work-item" target="_blank">
          <div class="work-info">
            <h5>University of Washington</h5>
           <!-- TODO: Replace with brief description -->
            <p>John Pyles</p>
            <!-- TODO: Replace with venue and year -->
            <!-- <span class="work-venue">Stanford University</span> -->
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        
      </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">CONFORM:<br> A Project to Create Crowd-Sourced Open Neuroscience fMRI Foundation Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://blahner.github.io/" target="_blank">Benjamin Lahner</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://andrewluo.net/" target="_blank">Andrew Luo</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://jacob-prince.github.io/" target="_blank">Jacob S Prince</a><sup>*</sup>,</span>
                  <span class="author-block">
                  <a href="https://mayukhdeb.github.io/" target="_blank">Mayukh Deb</a>,</span>
                  <span class="author-block">
                  <a href="https://www.hendersonneurolab.com/about/" target="_blank">Margaret M Henderson</a>,</span>
                  <span class="author-block">
                  <a href="https://psych.uw.edu/people/9200" target="_blank">John A Pyles</a>,</span>
                  <span class="author-block">
                  <a href="https://www.cs.cmu.edu/~lwehbe/" target="_blank">Leila Wehbe</a><sup>#</sup>,</span>
                  <span class="author-block">
                  <a href="http://olivalab.mit.edu/audeoliva.html" target="_blank">Aude Oliva</a><sup>#</sup>,</span>
                 <span class="author-block">
                  <a href="https://www.murtylab.com/" target="_blank">N. Apurva Ratan Murty</a><sup>#</sup>,</span>
                   <span class="author-block">
                  <a href="https://tarrlab.org" target="_blank">Michael J Tarr</a><sup>#</sup>,</span>
              </div>
                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">Foundation Models for the Brain and Body Workshop</span><br>
                    <span class="author-block">Data on the Brain & Mind Tutorial Track</span><br>
                    <span class="author-block">NeurIPS 2025</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>#</sup>Indicates Equal Senior Contribution</small></span>
                  </div>

      <p align="center">
        <img src="static/images/CONFORM.png" width="250px"></img>
      </p>
      
            <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>CONFORM Workshop Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/jacob-prince/PSN" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>MOSAIC Code</span>
                  </a>
                </span> -->

                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>MOSAIC arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
            <H2><b>CONFORM is built on these three amazing works:</b></H2>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>PSN Paper</span>
                      </a>
                    </span> -->

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                <span class="link-block">
                    <a href="https://github.com/jacob-prince/PSN" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>PSN</span>
                  </a>
                </span>

                <span class="link-block">
                    <a href="https://registry.opendata.aws/mosaic/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>MOSAIC</span>
                  </a>
                </span>

                <span class="link-block">
                    <a href="https://github.com/leomqyu/BraInCoRL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>BrainCoRL</span>
                  </a>
                </span>
                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>PSN arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
            
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser image -->
      <p align="center">
        <img src="static/images/Workshop-NeurIPS25.png" width="100%"></img>
      </p>
      <!-- TODO: Replace with your image description -->
      <h3 class="subtitle has-text-centered">
        <small></small><b>CONFORM workflow.</b> A single, optimized experimental design is distributed to multiple
sites for data collection. The collected data is then centralized for preprocessing, alignment, and
integration into a foundational dataset. This process creates a continuous feedback loop, allowing the
dataset to grow in size and diversity, which informs future experimental design and provides the basis
for a strong foundation model.</small>
      </h3>
    </div>
  </div>
</section>
<!-- End teaser -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            <small>We propose CONFORM (Crowd-Sourced Open Neuroscience fMRI Foundation Model),
a project that will bring together recent advances in neural data processing and analysis with
a novel, crowd-sourced infrastructure. This transformative approach will overcome several
current challenges in creating a foundational human fMRI model for vision: collecting
massive amounts of data from a handful of participants is neither scalable nor sustainable;
the number of participants is small for such datasets; stimulus diversity is limited; and
generalizability to different populations is poor. CONFORM will overcome these limitations
by combining a powerful generative denoising method (SNAP), a scalable framework for
aggregating existing fMRI datasets (MOSAIC), and a meta-learning model that enables
generalization with much smaller data from new participants (BraInCoRL). Our collabo-
rative effort will produce models built on unprecedented scale and diversity—ultimately
with hundreds of participants and hundreds of thousands of naturalistic image and movie
stimuli—and provide the tools for continuous expansion of the underlying dataset. This
“crowd-sourced” approach will allow many more researchers to leverage state-of-the-art
NeuroAI methods using the scale of data they typically collect, democratizing access to
powerful models and accelerating scientific discovery for a wide range of neuroscientific
domains and populations.</small>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h3 class="title">Background and Introduction</h2>

    <div class="content has-text-justified">
          <p><small>
            Creating a foundational human fMRI model is a critical next step for extending modern neuroAI. To achieve this, the model
            must generalize across both individuals and tasks, which requires a large volume of data with many participants,
            observations, and diverse stimuli. Historically, a significant impediment has been that most fMRI studies have small
            sample sizes and a low number of observations per session; the latter also leading to poor stimulus diversity. As a
            result, typical fMRI experiments sample only a tiny fraction of the human population and the vast space of real-world
            visual, auditory, or linguistic inputs. These limitations impeded efforts to draw robust conclusions from fMRI data and
            to integrate insights from modern AI systems into our understanding of the human brain—a challenge that is exacerbated by
            the inherently noisy BOLD signal.
            <br>

            In visual neuroscience, a first step in meeting this challenge has already been taken through the collection of
            large-scale fMRI datasets, which typically include brain responses from a small number of participants each scanned
            over many repeated sessions (15-40 hours-long sessions), who view a large number of stimuli (5000-10,000 stimuli per
            participant; e.g., BOLD5000, NSD, THINGS, NOD). This approach of ``deeply sampling'' a small number of participants
            increases the statistical power of experiments, and enables powerful parameter-rich, within-subject models. While
            this approach of collecting large datasets from small groups of participants has led to hundreds of publications and
            impactful discoveries, even this strategy is neither sustainable nor scalable for both scientific and practical reasons:
            <br>

            <ol>

            <li>Successful data collection at this scale depends on <it>heroic</it> efforts by both experimenters and participants.
            The time commitment and scheduling complexities are onerous: participants, experimenters, and scanners must remain
            consistently healthy and available (e.g., in both the BOLD5000 and NSD datasets at least one participant failed to
            complete the study; in the THINGS dataset one participant was canceled due to ``technical issues'').
            </li>
            
            <li>Even with this extraordinary amount of effort, data was collected from only 3-8 participants -- a small number that
            does not support the hoped-for population diversity expected of human neural foundation models.
            </li>

            <li>Stimulus diversity is necessarily limited by small participant pools and the need for stimulus repeats and/or overlap
            across participants. Even within a single recurring participant, only a limited number of observations
            are possible.<br>Moreover, controlled tasks and stimulus selection methods have further reduced diversity in the visual
            images included in each dataset: NSD uses only COCO images (only 80 object categories, which
            leave gaps in many regions of natural image space), BOLD5000 uses COCO as well as SUN and ImageNetimages, and THINGS
            uses a larger number of ``concepts'', but depicted as single cropped objects that show little context.
            </li>
    
            <li>Creating the infrastructure for data management and distribution is a considerable technical challenge. Short-term it
              requires a robust and replicable data processing pipeline and a reliable platform for data distribution. Long-term it requires
              stability—years later the distribution website should remain readily accessible.
            </li>
    
            <li>The monetary costs of collecting data can present a challenge to any single lab (e.g., five participants across 25 x one~hour
              scans could easily cost on the order of $100,000) and risks over-representing the interests of the small number of labs with
              the necessary resources.
            </li>

            </ol>
            Despite their increased scale relative to standard fMRI studies, these datasets still present significant challenges in the
            construction of NeuroAI models. The number of observations and participants is still small for purposes of model training, and
            data quality is dependent on preprocessing methods. More importantly, prediction accuracy and decoding performance are
            typically high only when trained and tested within the same participant—due to inherent structural and functional
            differences between individual brains and, at present, weak methods for generalizing across them. Consequently, when
            models are applied across participants, even within the same study, their performance and decoding capabilities decrease
            dramatically.
          </p>
            </small>
        </div>
      
      </div>
    </div>
  </section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h3 class="title">Towards a dynamic foundation model for vision fMRI</h2>

    <div class="content has-text-justified">
          <p><small>
            We propose CONFORM (Crowd-Sourced Open Neuroscience fMRI Foundation Model)--a strategy for building foundational human vision fMRI models through community-contributed datasets and models. Following previous efforts in systems neuroscience, we propose to leverage multi-site crowd-sourcing to enable collection of larger and more diverse datasets, along with new computational advances to facilitate coherent analysis. As detailed below, the building blocks of CONFORM are already in place, spanning four key domains:

    <ol>

    <li><i>A larger-scale and highly diverse dataset</i> that aggregates close to 100 participants and 100,000s of natural scenes depicting 1000's of object categories/concepts in context.  ``MOSAIC'' is a scalable framework for combining extant fMRI datasets, using common preprocessing and registration, into a single, extremely large-scale and extensible vision dataset. <a href="https://registry.opendata.aws/mosaic/">MOSAIC site</a></li>
    
    <li><i>Higher data quality</i> through an enhanced preprocessing pipeline to improve the signal-to-noise ratio of measured BOLD responses. Building on <a href="https://glmsingle.org">
<i>GLMSingle</i></a> and Generative Modeling of Signal and Noise (<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012092"><i>GSN</i></a>), we will develop <i>PSN</i> (Partitioning of Signal and Noise)--a powerful, generative low-rank denoising method that optimally separates signal from noise in neural data, outperforming trial-averaging and PCA, especially when noise is structured or complex (as in fMRI). <a href="https://github.com/jacob-prince/PSN">PSN site</a></li>
  
    <li><i>Enhanced generalization</i>
    to new participants from outside-of-dataset studies using ``BraInCoRL''--a meta-learned in-context foundation model that enables generalization using only a small amount of additional data. <a href="https://github.com/leomqyu/BraInCoRL">BrainCoRL site</a></li>
    
    <li><i>Crowd-sourcing infrastructure</i> to support the continuous integration of data from new studies across unique participants and data collection sites.</li>
            </ol>

Building on these methodological advances and the lessons learned from distributed large-scale fMRI datasets~\cite{chang2019bold5000,allen2022massive,things2023,gong_large-scale_2023,lahner_modeling_2024}, CONFORM will be a unique collaborative modeling strategy that will enable the creation of large-scale vision foundation fMRI models on datasets with improved signal quality, more participants, greater stimulus diversity, and which, critically, generalizes to new participants and studies in low data regimes. Longer term— across labs, participants, and MRI systems, we further propose a ``crowd-sourced'' community-driven effort to collect and integrate new data, thereby continuously improving the models. Given the challenges of collecting ever-larger and more diverse datasets at a single site, we suggest that crowd-sourcing is the only tenable solution for building appropriate-scale, truly foundational neural datasets. However, developing a viable crowd-sourcing infrastructure at this scale remains an unsolved challenge with a very high risk/reward tradeoff.

We are taking on this challenge by integrating and further developing recent advances in fMRI preprocessing, data aggregation, and generalization. CONFORM will also include the infrastructure for continuously expanding the dataset's size and the diversity of its stimuli~\cite{wang2022incorporating}. Our project will use a two-pronged approach for data contributions: locally directed and globally directed.

The \textit{locally directed} model is straightforward: the CONFORM distribution website will also accept contributions. In contrast to other neural data repositories~\cite{markiewicz2021openneuro}, we will provide detailed specifications for the acceptable designs, stimuli, tasks, and data formats to ensure submissions can be seamlessly integrated into CONFORM with high data quality. One attractive aspect of a locally directed model is that CONFORM may be able to re-purpose extant data that was already collected for a different purpose, thus giving new life to data that may have been otherwise dormant for years. 
At the same time, processing all available public data is not feasible. As an alternative, we will facilitate researchers re-analyzing their datasets with our pipeline.
Our goal with the locally directed model is to be as inclusive as possible with stimuli and tasks, even with necessary limitations.

The \textit{globally directed} model is more ambitious and forward-looking, and offers a greater potential payoff. We will provide a complete, turn-key study design to participating research sites, streamlining the data collection process (Fig. ~\ref{fig:teaser}). We will optimize the selection of stimulus images to achieve the best possible distribution of images within natural image space across many participants~\cite{rothsample}. We will also optimize for repeated stimuli and partial stimulus overlap across the population. Similarly, we will optimize the study design with respect to scanning parameters and trial structure. Collaborators will be able to specify both the length of scan sessions and the total number of participants they contribute. They will then be provided with complete scan protocols, experimental control files, and stimulus images. An interface on the same website used for distribution will allow them to download these files and upload their collected data for incorporation into the dataset.

CONFORM's framework towards a scalable foundation fMRI model will enable powerful insights into human vision. Datasets within CONFORM will continue to grow in size and stimulus diversity as the community contributes data. Critically, the resultant models will achieve improved generalization to new participants across diverse subpopulations, requiring only a relatively small amount of data per individual. As such, CONFORM will dramatically broaden the accessibility of NeuroAI methods, empowering researchers in a much wider range of scientific domains to make new discoveries.
            </small>
        </div>
      
      </div>
    </div>
  </section>

  
<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Workshop Paper</h2>

      <!-- TODO: Replace with your poster PDF -->
      <iframe  src="static/pdfs/NeurIPS_Foundation_Workshop_2025.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>
        @inproceedings{2025metalearning,
          title={Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex},
          author={Muquan Yu and Mu Nan and Hossein Adeli and Jacob S. Prince and John A. Pyles and Leila Wehbe and Margaret Marie Henderson and Michael J. Tarr and Andrew Luo},
          booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
          year={2025},
          url={https://openreview.net/forum?id=B3iPTZh7Za}
        }
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
